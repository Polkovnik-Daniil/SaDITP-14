{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce2f81b-49ec-4223-a3ac-fd290e25a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera.py\n",
    "\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PyQt5.QtCore import QThread, pyqtSignal\n",
    "\n",
    "\n",
    "class Camera(QThread):\n",
    "    \"\"\"Wraps cv2.VideoCapture and emits Qt signal with frames in RGB format.\n",
    "\n",
    "    The `run` function launches a loop that waits for new frames in the\n",
    "    VideoCapture and emits them with a `frame_received` signal.  Calling\n",
    "    `stop` stops the loop and releases the camera.\n",
    "    \"\"\"\n",
    "    frame_received = pyqtSignal(np.ndarray)\n",
    "    \"\"\"PyQt Signal emitting new frames read from the camera.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, video=0, parent=None):\n",
    "        \"\"\"Initialize Camera instance.\n",
    "\n",
    "        Args:\n",
    "            video (int or string): ID of camera or video filename\n",
    "            parent (QObject): parent object in Qt context\n",
    "        \"\"\"\n",
    "        super().__init__(parent=parent)\n",
    "\n",
    "        self._cap = cv2.VideoCapture(video)\n",
    "        self._running = False\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Start loop in thread capturing incoming frames.\n",
    "        \"\"\"\n",
    "        self._running = True\n",
    "        while self._running:\n",
    "            ret, frame = self._cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                self._running = False\n",
    "                raise RuntimeError(\"No frame received\")\n",
    "\n",
    "            self.frame_received.emit(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop loop and release camera.\n",
    "        \"\"\"\n",
    "        self._running = False\n",
    "        time.sleep(0.1)\n",
    "        self._cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86b59b2-d65a-4dd2-9a5d-12029575b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rppg.py\n",
    "\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from PyQt5.QtCore import pyqtSignal, QObject\n",
    "import mediapipe as mp\n",
    "\n",
    "# from camera import Camera\n",
    "\n",
    "RppgResults = namedtuple(\"RppgResults\", [\"rawimg\", \"landmarks\"])\n",
    "\n",
    "class RPPG(QObject):\n",
    "\n",
    "    rppg_updated = pyqtSignal(RppgResults)\n",
    "\n",
    "    def __init__(self, parent=None, video=0):\n",
    "        \"\"\"rPPG model processing incoming frames and emitting calculation\n",
    "        outputs.\n",
    "\n",
    "        The signal RPPG.updated provides a named tuple RppgResults containing\n",
    "          - rawimg: the raw frame from camera\n",
    "          - landmarks: multiface_landmarks object returned by FaceMesh\n",
    "        \"\"\"\n",
    "        super().__init__(parent=parent)\n",
    "\n",
    "        self._cam = Camera(video=video, parent=parent)\n",
    "        self._cam.frame_received.connect(self.on_frame_received)\n",
    "\n",
    "        self.detector = mp.solutions.face_mesh.FaceMesh(\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=False,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "    def on_frame_received(self, frame):\n",
    "        \"\"\"Process new frame - find face mesh and emit outputs.\n",
    "        \"\"\"\n",
    "        rawimg = frame.copy()\n",
    "        results = self.detector.process(frame)\n",
    "\n",
    "        self.rppg_updated.emit(RppgResults(rawimg, results))\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Launch the camera thread.\n",
    "        \"\"\"\n",
    "        self._cam.start()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the camera thread and clean up the detector.\n",
    "        \"\"\"\n",
    "        self._cam.stop()\n",
    "        self.detector.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071a4147-3dc1-4e4f-b3b2-75c61629a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mainwindow.py\n",
    "\n",
    "from PyQt5.QtWidgets import QMainWindow\n",
    "import pyqtgraph as pg\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "    def __init__(self, rppg):\n",
    "        \"\"\"MainWindow visualizing the output of the RPPG model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        rppg.rppg_updated.connect(self.on_rppg_updated)\n",
    "        self.init_ui()\n",
    "\n",
    "    def on_rppg_updated(self, output):\n",
    "        \"\"\"Update UI based on RppgResults.\n",
    "        \"\"\"\n",
    "        img = output.rawimg.copy()\n",
    "        draw_facemesh(img, output.landmarks, tesselate=True, contour=True)\n",
    "        self.img.setImage(img)\n",
    "\n",
    "\n",
    "    def init_ui(self):\n",
    "        \"\"\"Initialize window with pyqtgraph image view box in the center.\n",
    "        \"\"\"\n",
    "        self.setWindowTitle(\"FaceMesh detection in PyQt\")\n",
    "\n",
    "        layout = pg.GraphicsLayoutWidget()\n",
    "        self.img = pg.ImageItem(axisOrder=\"row-major\")\n",
    "        vb = layout.addViewBox(invertX=True, invertY=True, lockAspect=True)\n",
    "        vb.addItem(self.img)\n",
    "\n",
    "        self.setCentralWidget(layout)\n",
    "\n",
    "\n",
    "def draw_facemesh(img, results, tesselate=False,\n",
    "                  contour=False, irises=False):\n",
    "    \"\"\"Draw all facemesh landmarks found in an image.\n",
    "\n",
    "    Irises are only drawn if the corresponding landmarks are present,\n",
    "    which requires FaceMesh to be initialized with refine=True.\n",
    "    \"\"\"\n",
    "    if results is None or results.multi_face_landmarks is None:\n",
    "        return\n",
    "\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        if tesselate:\n",
    "            mp.solutions.drawing_utils.draw_landmarks(\n",
    "                image=img,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles\n",
    "                .get_default_face_mesh_tesselation_style())\n",
    "        if contour:\n",
    "            mp.solutions.drawing_utils.draw_landmarks(\n",
    "                image=img,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp.solutions.drawing_styles\n",
    "                .get_default_face_mesh_contours_style())\n",
    "        if irises and len(face_landmarks) > 468:\n",
    "            mp.solutions.drawing_utils.draw_landmarks(\n",
    "                image=img,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles\n",
    "                .get_default_face_mesh_iris_connections_style())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffebfa8-dbcf-45d6-9530-e02c23489062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "from PyQt5.QtWidgets import QApplication\n",
    "\n",
    "# from mainwindow import MainWindow\n",
    "# from rppg import RPPG\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication([])\n",
    "    rppg = RPPG(video=0, parent=app)\n",
    "    win = MainWindow(rppg=rppg)\n",
    "    win.show()\n",
    "\n",
    "    rppg.start()\n",
    "    app.exec_()\n",
    "    rppg.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1af7fb0-65a9-4ec4-a58e-0784d2e52900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
